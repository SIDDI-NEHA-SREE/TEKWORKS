# -*- coding: utf-8 -*-
"""D9(01).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y6-OI2q0PhN4273Ow0Ldt0-W6-pnGZdG

‚ÄúE-Commerce Transaction Analytics‚Äù (Using Online Retail Dataset)

üéØ Scenario / Story
You are a data analyst at ShopWave, an e-commerce platform in the UK. ShopWave logs every transaction (order) made in their store. Each record has:

Invoice number  
Stock code / product ID  
Description   
Quantity    
Invoice date   
Unit price   
Customer ID   
Country

Your manager wants you to clean the data, fix inconsistencies, derive business metrics, and explore relationships. The cleaned data should enable deeper dashboards later.

Tasks & Steps    
Below is a full pipeline of tasks that students should perform. Each task corresponds to one or more of the functions/techniques you already taught.   
Load & Inspect   
Read the CSV (e.g. OnlineRetail.csv)   
Display head(),   
 tail(),  
   info(),   
 shape   
Check dtypes    
Missing Data Handling   
Use isnull().sum() to find missing values (e.g. some Description or Customer ID missing)   
Drop rows that have missing Customer ID (because you can‚Äôt tie to a customer)       
Fill missing Description or other columns using a placeholder (e.g. "Unknown")      
Date Parsing / Format Correction
The InvoiceDate column might be string. Convert using pd.to_datetime(..., format='mixed')     
Drop records where parsing failed (if any)
Detect & Fix Bad or Outlier Data     
Some transactions might have negative quantity (returns) ‚Äî detect        those and decide whether to treat as returns or drop
Some unit prices might be zero or negative ‚Äî fix/clean these (e.g. drop or adjust)     
Duplicates     
Use duplicated() to find duplicated invoice-item entries    
Drop duplicates
"""

pip install pandas

import pandas as pd
import numpy as np
data=pd.read_csv("/content/OnlineRetail.csv", encoding='latin1')
df=pd.DataFrame(data)
df.head()

df.tail()

print(df.shape)
print(df.info())

df.isnull().sum()

df = df.dropna(subset=['CustomerID'])
df['Description'] = df['Description'].fillna("Unknown")

df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')
df = df.dropna(subset=['InvoiceDate'])

print(df[df['Quantity'] < 0].shape[0])
returns = df[df['Quantity'] < 0]
df = df[df['Quantity'] > 0]

duplicates = df.duplicated().sum()
print(f"Duplicate rows: {duplicates}")

df = df.drop_duplicates()

df.to_csv("OnlineRetail_Cleaned.csv", index=False)

"""Filtering & Sorting    
Filter transactions where Quantity > 1000 (suspicious outliers)
Sort by UnitPrice * Quantity descending (i.e. highest revenue orders)
Merge / Enrich Data        
Create a small custom DataFrame product_info with columns StockCode, Category, Supplier                  
Convert its date (if needed) and merge with the main dataset on StockCode (left join)               
Group & Aggregation               
Group by Country and compute total revenue, mean revenue per order, and count of orders            
Create a new column Revenue = Quantity * UnitPrice         
Use pd.cut() to bucket UnitPrice (e.g. cheap, medium, expensive) and then group by that price range to see how many purchases and average revenue                
Correlation / Relationships              
Use .corr() on numeric columns (Quantity, UnitPrice, Revenue)        
Interpret which factors are strongly related (e.g. high quantity often correlates with higher revenue)         
Rename & String Operations                
Rename StockCode to Product_ID, UnitPrice to Price               
Use .str methods on Description ‚Äî e.g., .str.lower(), .str.contains("glass"), etc.               
Filter products whose description contains certain keywords
"""

filtered_df = df[df['Quantity'] > 1000]
print("Transactions with Quantity > 1000:")
display(filtered_df.head())

df['Revenue'] = df['UnitPrice'] * df['Quantity']
sorted_df = df.sort_values(by='Revenue', ascending=False)
print("\nDataFrame sorted by Revenue (descending):")
display(sorted_df.head())

product_info = pd.DataFrame({
    'StockCode': ['85123A', '71053', '84406B', '84029G', '84029E'],
    'Category': ['Home Decor', 'Home Decor', 'Home Decor', 'Textiles', 'Textiles'],
    'Supplier': ['Supplier A', 'Supplier B', 'Supplier A', 'Supplier C', 'Supplier C']
})

merged_df = pd.merge(df, product_info, on='StockCode', how='left')

print("DataFrame after merging with product_info:")
display(merged_df.head())

"""Descriptive Statistics              
Use .describe() on numeric columns                   
Use .value_counts() on Country or Category                 
Advanced Filtering / Querying                 
Use .query() to find orders where Revenue > 1000 and Country == 'Germany'                      
Use .between() to capture Quantity between 10 and 100                    
Export Cleaned Data              
Save the final cleaned & enriched dataset to CSV / Excel

"""

correlation_matrix = df[['Quantity', 'Price', 'Revenue']].corr()

print("\nCorrelation matrix of numeric columns:")
display(correlation_matrix)

print(f"\nRows with UnitPrice <= 0 before removal: {df[df['Price'] <= 0].shape[0]}")
df = df[df['Price'] > 0]
print(f"Rows remaining after removing UnitPrice <= 0: {df.shape[0]}")
display(df.head())

df = df.rename(columns={'StockCode': 'Product_ID', 'UnitPrice': 'Price'})
print("\nDataFrame after renaming columns:")
display(df.head())

df['Description'] = df['Description'].str.lower()
print("\nDataFrame after converting Description to lowercase:")
display(df.head())

glass_products = df[df['Description'].str.contains("glass", na=False)]
print("\nProducts with 'glass' in their description:")
display(glass_products.head())

bins = [0, 5, 20, df['Price'].max()]
labels = ['cheap', 'medium', 'expensive']
df['Price_Range'] = pd.cut(df['Price'], bins=bins, labels=labels, right=False)

price_range_agg = df.groupby('Price_Range').agg(
    number_of_purchases=('InvoiceNo', 'count'),
    average_revenue=('Revenue', 'mean')
).reset_index()
print("\nAggregated data by Price Range:")
display(price_range_agg)

country_agg = df.groupby('Country').agg(
    total_revenue=('Revenue', 'sum'),
    mean_revenue_per_order=('Revenue', 'mean'),
    order_count=('InvoiceNo', 'nunique')
).reset_index()

print("\nAggregated data by Country:")
display(country_agg.head())

display(df.describe())

display(df['Country'].value_counts().head())
display(df['Product_ID'].value_counts().head())

query_result = df.query("Revenue > 1000 and Country == 'Germany'")
display(query_result.head())

between_quantity = df[df['Quantity'].between(10, 100)]
display(between_quantity.head())

df.to_csv("OnlineRetail_Fully_Cleaned.csv", index=False)